{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0493a518-ee77-487c-84ba-a4d0148bef45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Comparison Plot : Progressive Passes V Progressive Carries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e62654-a814-4556-b28b-b02dc2c0e535",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'select_one'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categories:\n\u001b[1;32m---> 39\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     data[category] \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     41\u001b[0m     data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_urls\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murls\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m, in \u001b[0;36mscrape_category\u001b[1;34m(category)\u001b[0m\n\u001b[0;32m     21\u001b[0m         category_html \u001b[38;5;241m=\u001b[39m BeautifulSoup(comment, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mcategory_html\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_one\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#div_stats_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(\u001b[38;5;28mstr\u001b[39m(table))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m urls \u001b[38;5;241m=\u001b[39m [a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m category_html\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtd[data-stat=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] a\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'select_one'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "# Function to scrape data from fbref\n",
    "def scrape_category(category):\n",
    "    url = f\"https://fbref.com/en/comps/676/{category}/European-Championship-Stats\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    category_html = None\n",
    "    for comment in comments:\n",
    "        if f\"div_stats_{category}\" in comment:\n",
    "            category_html = BeautifulSoup(comment, 'html.parser')\n",
    "            break\n",
    "\n",
    "    table = category_html.select_one(f\"#div_stats_{category} table\")\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "    df.columns = [col.split('_')[-1] if col.startswith('Unnamed') else col for col in df.columns]\n",
    "\n",
    "    urls = [a['href'] for a in category_html.select(\"td[data-stat='player'] a\")]\n",
    "\n",
    "    output = {'df': df, 'urls': urls}\n",
    "    return output\n",
    "\n",
    "categories = [\"passing\", \"possession\", \"gca\"]\n",
    "\n",
    "data = {}\n",
    "for category in categories:\n",
    "    output = scrape_category(category)\n",
    "    data[category] = output['df']\n",
    "    data[f\"{category}_urls\"] = output['urls']\n",
    "\n",
    "df_list = []\n",
    "# Loop through each URL in the list\n",
    "for url in data['passing_urls']:\n",
    "  url_parts = url.split('/')\n",
    "  \n",
    "  # Extract player ID (assuming alphanumeric)\n",
    "  player_id = url_parts[-2]\n",
    "  \n",
    "  # Extract player name (assuming everything after last '/')\n",
    "  player_name = url_parts[-1]\n",
    "  \n",
    "  # Create a dictionary with extracted data\n",
    "  player_dict = {'url': url, 'playerId': player_id, 'playerName': player_name}\n",
    "  \n",
    "  # Append the dictionary to the list\n",
    "  df_list.append(player_dict)\n",
    "\n",
    "# Create the DataFrame from the list of dictionaries\n",
    "df_passing_urls = pd.DataFrame(df_list)\n",
    "\n",
    "df_list = []\n",
    "# Loop through each URL in the list\n",
    "for url in data['possession_urls']:\n",
    "  url_parts = url.split('/')\n",
    "  \n",
    "  # Extract player ID (assuming alphanumeric)\n",
    "  player_id = url_parts[-2]\n",
    "  \n",
    "  # Extract player name (assuming everything after last '/')\n",
    "  player_name = url_parts[-1]\n",
    "  \n",
    "  # Create a dictionary with extracted data\n",
    "  player_dict = {'url': url, 'playerId': player_id, 'playerName': player_name}\n",
    "  \n",
    "  # Append the dictionary to the list\n",
    "  df_list.append(player_dict)\n",
    "\n",
    "# Create the DataFrame from the list of dictionaries\n",
    "df_possession_urls = pd.DataFrame(df_list)\n",
    "\n",
    "passing = data['passing']\n",
    "possession = data['possession']\n",
    "passing['Total_Cmp'] = pd.to_numeric(passing['Total_Cmp'], errors='coerce') # Cmp : Completed total passes\n",
    "passing['PrgP'] = pd.to_numeric(passing['PrgP'], errors='coerce') # PrgP : Progressive passes\n",
    "passing['prog_pct'] = passing['PrgP'] / passing['Total_Cmp']\n",
    "passing = passing[['Player', 'Squad', 'Total_Cmp', 'PrgP', 'prog_pct']]\n",
    "passing.columns = ['player', 'team', 'passes', 'prog_passes', 'prog_pct']\n",
    "#passing = passing.dropna().reset_index(drop=True)\n",
    "passing = passing.loc[passing['player'] != 'Player'].reset_index(drop=True) # Filtering out rows where player names are not found\n",
    "passing = pd.concat([passing,df_passing_urls],axis=1)\n",
    "passing = passing[passing['passes'] != 0].reset_index(drop=True) # Filtering out rows for players who made 0 passes so far\n",
    "\n",
    "possession['Carries_Carries'] = pd.to_numeric(possession['Carries_Carries'], errors='coerce')\n",
    "possession['Carries_PrgC'] = pd.to_numeric(possession['Carries_PrgC'], errors='coerce') # PrgC : Progressive Carries\n",
    "possession['prog_pct'] = possession['Carries_PrgC'] / possession['Carries_Carries']\n",
    "possession = possession[['Player', 'Squad', 'Carries_Carries', 'Carries_PrgC', 'prog_pct']]\n",
    "possession.columns = ['player', 'team', 'carries', 'prog_carries', 'prog_pct']\n",
    "#possession = possession.dropna().reset_index(drop=True)\n",
    "possession = possession[possession['player'] != 'Player'].reset_index(drop=True)\n",
    "possession = pd.concat([possession,df_possession_urls],axis=1)\n",
    "possession = possession[possession['carries'] != 0].reset_index(drop=True)\n",
    "\n",
    "passes_filt = passing[(passing['passes'] >= 50) & (passing['prog_pct'] > 0) & (passing['prog_pct'] < 1)]\n",
    "carry_filt = possession[(possession['carries'] >= 50) & (possession['prog_pct'] > 0) & (possession['prog_pct'] < 1)]\n",
    "\n",
    "pass_alpha, pass_beta, _, _ = beta.fit(passes_filt['prog_pct'], floc=0, fscale=1)\n",
    "carry_alpha, carry_beta, _, _ = beta.fit(carry_filt['prog_pct'], floc=0, fscale=1)\n",
    "\n",
    "passing['adj_prog_pct'] = (passing['prog_passes'] + pass_alpha) / (passing['passes'] + pass_alpha + pass_beta)\n",
    "possession['adj_prog_pct'] = (possession['prog_carries'] + carry_alpha) / (possession['carries'] + carry_alpha + carry_beta)\n",
    "\n",
    "passing['adj_prog_pct'] = (passing['adj_prog_pct'] - passing['adj_prog_pct'].mean()) / passing['adj_prog_pct'].std()\n",
    "possession['adj_prog_pct'] = (possession['adj_prog_pct'] - possession['adj_prog_pct'].mean()) / possession['adj_prog_pct'].std()\n",
    "\n",
    "passes_final = passing[['player', 'team', 'url', 'adj_prog_pct']].sort_values(by='adj_prog_pct', ascending=False)\n",
    "possession_final = possession[['player', 'team', 'url', 'adj_prog_pct']].sort_values(by='adj_prog_pct', ascending=False)\n",
    "\n",
    "passes_final.columns = ['player', 'team', 'url', 'pass_metric']\n",
    "possession_final.columns = ['player', 'team', 'url', 'carry_metric']\n",
    "\n",
    "passes_final['id'] = passes_final['url'].apply(lambda x: re.search(r\"(?<=players/)\\w+\", x).group())\n",
    "passes_final['headshot_url'] = \"https://fbref.com/req/202302030/images/headshots/\" + passes_final['id'] + \"_2022.jpg\"\n",
    "\n",
    "possession_final['id'] = possession_final['url'].apply(lambda x: re.search(r\"(?<=players/)\\w+\", x).group())\n",
    "possession_final['headshot_url'] = \"https://fbref.com/req/202302030/images/headshots/\" + possession_final['id'] + \"_2022.jpg\"\n",
    "\n",
    "flags = pd.read_csv(\"flags_iso.csv\")[['Alpha-2 code', 'URL']]\n",
    "flags.columns = ['team', 'flag']\n",
    "\n",
    "passes_final['team'] = passes_final['team'].str.upper().str[:2]\n",
    "possession_final['team'] = possession_final['team'].str.upper().str[:2]\n",
    "\n",
    "passes_final = passes_final.merge(flags, how='left', left_on='team', right_on='team')\n",
    "passes_final['flag'] = passes_final['flag'].fillna(\"https://cdn.britannica.com/44/344-004-494CC2E8/Flag-England.jpg\")\n",
    "passes_final['pass_metric'] = passes_final['pass_metric'].round(2)\n",
    "\n",
    "possession_final = possession_final.merge(flags, how='left', left_on='team', right_on='team')\n",
    "possession_final['flag'] = possession_final['flag'].fillna(\"https://cdn.britannica.com/44/344-004-494CC2E8/Flag-England.jpg\")\n",
    "possession_final['carry_metric'] = possession_final['carry_metric'].round(2)\n",
    "\n",
    "t10_pass = passes_final.head(10)\n",
    "t10_carry = possession_final.head(10)\n",
    "\n",
    "final_stats = pd.merge(passes_final, possession_final, on=['headshot_url', 'player', 'flag'])\n",
    "\n",
    "passes_100 = passing[passing['passes'] >= 100]\n",
    "carries_100 = possession[possession['carries'] >= 100]\n",
    "\n",
    "final_stats = final_stats[final_stats['player'].isin(passes_100['player']) & final_stats['player'].isin(carries_100['player'])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "fig.set_facecolor('black')\n",
    "ax.set_facecolor('black')\n",
    "ax.grid(color='white', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "for index,row in final_stats.iterrows():\n",
    "  if ((row['pass_metric'] >= 0.0) & (row['carry_metric'] >= 0.5)) or (row['pass_metric'] >= 1.5) or (row['carry_metric'] >= 1.5):\n",
    "    ax.scatter(row['pass_metric'], row['carry_metric'],color='red')\n",
    "    ax.annotate(row['player'],xy = (row['pass_metric']+0.05,row['carry_metric']+0.05),color='white',fontsize=15)\n",
    "  else:\n",
    "    ax.scatter(row['pass_metric'], row['carry_metric'],color='red')\n",
    "\n",
    "\n",
    "#ax.tick_params(axis='x', colors='white')\n",
    "#ax.tick_params(axis='y', colors='white')\n",
    "ax.spines['top'].set_color('white')\n",
    "ax.spines['right'].set_color('white')\n",
    "ax.spines['bottom'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "\n",
    "ax.set_xlabel(\"Progressive Playmaking Value (Passing)\",fontsize=20,color='white')\n",
    "ax.set_ylabel(\"Progressive Playmaking Value (Carrying)\",fontsize=20,color='white')\n",
    "ax.set_title(\"Comparing Progressive Playmaking Values: Passing vs Carrying\",fontsize=20,color='white')\n",
    "plt.suptitle(\"Players With 100+ Passes and Carries In The Group Stage\",fontsize=25,color='white')\n",
    "fig.text(0.5, 0, \"Data from FBRef | Ishdeep Chahda | @indian_citizen\", ha='center', fontsize=10,color='white')\n",
    "plt.savefig(\"comp_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
